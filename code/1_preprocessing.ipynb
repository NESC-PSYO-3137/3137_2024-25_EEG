{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG - ERP Preprocessing Script\n",
    "\n",
    "This script is a preprocessing script for EEG data. The file you're seeing is called a [Jupyter notebook](https://jupyter.org/), which is a way to write and run Python code in a way that is easy to read and understand.\n",
    "\n",
    "Even if you've never used Python, you can use this notebook to preprocess EEG data. You can run the code in each cell by clicking on the cell and pressing `Shift + Enter`.\n",
    "\n",
    "This script is designed to be used with the [MNE-Python](https://mne.tools/stable/index.html) library. MNE-Python is a powerful library for analyzing EEG data, and it has many built-in functions for preprocessing, visualization, and analysis.\n",
    "\n",
    "The first thing we need to do is install MNE-Python. You can do this by running the cell below. (Remember to press `Shift + Enter` to run the code in the cell.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import mne_bids\n",
    "import os.path as op\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "mne.set_log_level('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'sub-000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get EEG data\n",
    "\n",
    "Data are stored on a service called GitHub. The command below will copy the data to your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NESC-PSYO-3137/3137_2024-25_EEG.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load EEG data\n",
    "\n",
    "Raw EEG data is typically stored in a one or more files containing continuous EEG data. There are many different proprietary file formats for EEG data; most of these are developed by the manufacturer of a particular EEG system, since an integral part of an EEG system is software to save the data for later analysis. Fortunately, MNE provides functions to import data from most common EEG systems. \n",
    "\n",
    "In the present case, we are working with data from a system sold by Brain Products, whose software is called *Brain Vision*. So we will use MNE's `read_raw_brainvision()` function. The Brain Vision format actually specifies *three files* for any given data set. The three files are all created at the time that the EEG data is acquired, and it's important to ensure that all three are copied when moving them around. The files are as follows:\n",
    "- `*.eeg` is the actual EEG data (electrical potential measurements for all electrodes, at all time points). This is stored in a compressed (binary) format\n",
    "- `*.vmrk` is a text file containing all of the markers (*trigger codes*) that were sent to the EEG system during data collection, by the stimulus computer. These typically encode the onset of various stimuli, and times of any responses by the participant, as well as and what each stimulus/response was. \n",
    "- `*.vhdr` is a text file with header information, or **metadata** about the data set, including technical details such as the sampling rate, and the settings of the EEG amplifier during the recording. The `.vhdr` file is particularly important because it specifies the file names of the `.eeg` and `.vmrk` files (although they should always be named consistently with the header file). \n",
    "\n",
    "When we run `read_raw_brainvision()` the file we will actually pass as an argument is the `.vhdr` file. Since it specifies the names of the associated `.eeg` and `.vmrk` files, from this file MNE can find the data and markers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = glob(op.join('3137_2024-25_EEG/data/', subject, 'eeg', subject + '*.set'))[0]\n",
    "in_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_eeglab(in_file, \n",
    "                             eog='auto', \n",
    "                             \n",
    "                             preload=True)\n",
    "raw.rename_channels({'FP1':'Fp1', 'FP2':'Fp2'})\n",
    "raw.set_montage('standard_1020')\n",
    "raw = mne.set_bipolar_reference(raw, \n",
    "                                ['HEOG_left', 'VEOG_lower'], \n",
    "                                ['HEOG_right', 'Fp1'],\n",
    "                                ['HEOG', 'VEOG']\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View raw file metadata\n",
    "\n",
    "We can view some of the information about the data that's stored with it in the file: the sampling rate, the number of channels, and the names of the channels. This information is stored in the `info` attribute of the `raw` object. We can access it by typing `raw.info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot channel locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_sensors(show_names=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot power spectral density\n",
    "This is the frequency-domain representation of the EEG data. It shows how much power is present in the EEG signal at each frequency. This can be useful for identifying artifacts in the data, as well as for understanding the frequency content of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.compute_psd(fmax=80).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bandpass filter the data and replot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.filter(0.1, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.compute_psd(fmax=80).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event processing\n",
    "\n",
    "Find event markers in data, and label them appropriately. This is a crucial step in EEG data analysis, because it allows us to segment the data into epochs, which are time-locked to the onset of a stimulus or response. This is the basis for all further analysis of EEG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "event_id_map = {'111': 'prime/related/list1',\n",
    "                '112': 'prime/related/list2',\n",
    "                '121': 'prime/unrelated/list1',\n",
    "                '122': 'prime/unrelated/list2',\n",
    "                '211': 'target/related/list1',\n",
    "                '212': 'target/related/list2',\n",
    "                '221': 'target/unrelated/list1',\n",
    "                '222': 'target/unrelated/list2',\n",
    "                '201': 'resp/correct/list1',\n",
    "                '202': 'resp/incorrect/list2'\n",
    "                }\n",
    "\n",
    "# map values of event_id_map to keys of event_id and save as event_id_new\n",
    "event_id_new = {event_id_map[key]: value for key, value in event_id.items()}\n",
    "\n",
    "event_id_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch the data\n",
    "\n",
    "This is the process of cutting the continuous EEG data into segments, or epochs, that are time-locked to the onset of a stimulus or response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = -0.100\n",
    "tmax =  1.000\n",
    "epochs_ica = mne.Epochs(raw.copy().filter(1, 30), \n",
    "                        events, event_id_new, \n",
    "                        tmin=tmin, tmax=tmax, \n",
    "                        baseline=(None, 0), \n",
    "                        preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.average().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.average().plot(picks=['Cz'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_ica.average().plot(picks=['Fp2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ICA\n",
    "\n",
    "Independent Component Analysis (ICA) is a method for separating the EEG signal into independent components, each of which represents a different source of neural activity. This can be useful for removing artifacts from the data, such as eye blinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = mne.preprocessing.ICA(n_components=.975, \n",
    "                             random_state=42, \n",
    "                             max_iter='auto'\n",
    "                             )\n",
    "ica.fit(epochs_ica,\n",
    "        decim=3, \n",
    "        picks=['eeg']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and remove ocular ICA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = []\n",
    "num_excl = 0\n",
    "z_thresh = 4\n",
    "z_step = .25\n",
    "\n",
    "while num_excl < 1 and z_thresh > 0:\n",
    "    eog_indices, eog_scores = ica.find_bads_eog(epochs_ica, threshold=z_thresh)\n",
    "    num_excl = len(eog_indices)\n",
    "    z_thresh -= z_step # won't impact things if num_excl is ≥ n_max_eog \n",
    "\n",
    "ica.exclude = eog_indices\n",
    "z_thresh_final = round(z_thresh + z_step, 2)\n",
    "print(num_excl, 'components excluded with z_thresh =', z_thresh_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_eog_scores = ica.plot_scores(eog_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the scalp distribution of each ICA component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.plot_components()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create epochs for visualization and analysis\n",
    "\n",
    "These are filtered differently from how it was done for ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(raw,\n",
    "                    events, event_id_new, \n",
    "                    tmin=tmin, tmax=tmax, \n",
    "                    baseline=(None, 0), \n",
    "                    preload=True)\n",
    "\n",
    "ica.apply(epochs);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare average of all epochs before and after ICA correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "epochs_ica.average().plot(axes=axs[0], titles='Before ICA', show=False)\n",
    "epochs.average().plot(axes=axs[1], titles='After ICA', show=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-reference the data to averaged mastoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_rr = epochs.set_eeg_reference(['P9', 'P10'])\n",
    "\n",
    "derivatives_path = op.join('..', 'derivatives', subject)\n",
    "if Path(derivatives_path).exists() == False:\n",
    "    Path(derivatives_path).mkdir(parents=True)\n",
    "epochs_rr.save(op.join(derivatives_path, subject + '-epo.fif'), overwrite=True)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "epochs.average().plot(axes=axs[0], titles='Before rereference', show=False)\n",
    "epochs_rr.average().plot(axes=axs[1], titles='After rereference', show=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average across trials for each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_of_interest = ['prime/related', 'prime/unrelated', 'target/related', 'target/unrelated']\n",
    "evoked = {}\n",
    "for condition in cond_of_interest:\n",
    "    evoked[condition] = epochs_rr[condition].average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot average ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Cz', 'CPz', 'Pz']\n",
    "mne.viz.plot_compare_evokeds({c:evoked[c] for c in cond_of_interest},\n",
    "                              picks=roi, combine='mean',\n",
    "                              show_sensors='lower right', legend='lower center', \n",
    "                              ci=False,\n",
    "                            );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute difference waves between conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = {'related': ['prime/related', 'target/related'],\n",
    "             'unrelated': ['prime/unrelated', 'target/unrelated'],\n",
    "             'mismatch': ['target/unrelated', 'target/related']\n",
    "             }\n",
    "\n",
    "evoked_diff = {}\n",
    "for contrast, conditions in contrasts.items():\n",
    "  evoked_diff[contrast] = [mne.combine_evoked([evoked[conditions[0]], evoked[conditions[1]]],\n",
    "                                              weights=[1, -1])\n",
    "\n",
    "                            ]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot difference waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = ['Cz', 'CPz', 'Pz']\n",
    "mne.viz.plot_compare_evokeds(evoked_diff, \n",
    "                             picks=roi, \n",
    "                             show_sensors='upper left', \n",
    "                             legend='upper right',\n",
    "                             combine='mean',\n",
    "                            #  ylim = {'eeg': (-3, 3)}\n",
    "                             )\n",
    "                             \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot scalp topographies of difference waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(tmin, tmax, .100)\n",
    "uv_range = 15\n",
    "\n",
    "for contrast in contrasts:\n",
    "  print('\\n', contrast)\n",
    "  evoked_diff[contrast][0].plot_topomap(times, \n",
    "                                       ch_type='eeg', \n",
    "                                       vlim=[-uv_range, uv_range], \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
